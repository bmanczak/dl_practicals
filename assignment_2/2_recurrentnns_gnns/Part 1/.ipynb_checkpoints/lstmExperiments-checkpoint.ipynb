{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# datasets\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Using device cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device which to run the model on\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"[INFO]: Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RandomCombinationsDataset(seq_length)\n",
    "dataloader =  DataLoader(dataset, 8, num_workers=1, drop_last=True)\n",
    "\n",
    "x,y = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module implements a LSTM model in PyTorch.\n",
    "You should fill in code into indicated sections.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "use this for weight init torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "use \n",
    "stdv = 1.0 / math.sqrt(self._hidden_dim)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_length, input_dim, hidden_dim, num_classes,\n",
    "                 batch_size, device):\n",
    "\n",
    "        # super(LSTM, self).__init__()\n",
    "        super().__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(seq_length, input_dim)\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "        # Input modulation gate\n",
    "        self.W_gx = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_gh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_g = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Input gate\n",
    "        self.W_ix = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_ih = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Forget gate\n",
    "        self.W_fx = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_fh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Output gate\n",
    "        self.W_ox = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_oh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Output calculation\n",
    "        self.W_ph = nn.Parameter(torch.Tensor(hidden_dim, num_classes))\n",
    "        self.b_p = nn.Parameter(torch.Tensor(num_classes))\n",
    "\n",
    "        self.kaiming_init()\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def kaiming_init(self):\n",
    "        for p in self.parameters():\n",
    "            if len(p.size()) == 2:\n",
    "                p.data.normal_(0, 1 / math.sqrt(self.hidden_dim))\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h_t = torch.zeros(self.hidden_dim).to(self.device)\n",
    "        c_t = torch.zeros(self.hidden_dim).to(self.device)\n",
    "        print\n",
    "        x = self.embeddings(x.long())\n",
    "\n",
    "        for time in range(self.seq_length - 1):\n",
    "            x_t = x[:, time, :]\n",
    "            # Input modulation gate\n",
    "            g_t = torch.tanh(x_t @ self.W_gx + h_t @ self.W_gh + self.b_g)\n",
    "            # Input gate\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ix + h_t @ self.W_ih + self.b_i)\n",
    "            # Forget gate\n",
    "            f_t = torch.sigmoid(x_t @ self.W_fx + h_t @ self.W_fh + self.b_f)\n",
    "            # Output gate\n",
    "            o_t = torch.sigmoid(x_t @ self.W_ox + h_t @ self.W_oh + self.b_o)\n",
    "            # Cell state\n",
    "            c_t = g_t * i_t + c_t * f_t\n",
    "            h_t = torch.tanh(c_t) * o_t\n",
    "\n",
    "        out = self.logSoftmax((h_t @ self.W_ph + self.b_p))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(seq_length=seq_length, input_dim=1, hidden_dim = 128, num_classes= seq_length,\n",
    "            batch_size = 128, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = nn.Embedding(11, 3)\n",
    "embeddings(x.long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_length, input_dim, hidden_dim, num_classes,\n",
    "                 batch_size, device):\n",
    "        super(biLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.lstm_cell = LSTMCell(seq_length, input_dim, hidden_dim, num_classes,\n",
    "                                  batch_size, device)\n",
    "\n",
    "        # Output calculation\n",
    "        self.W_ph = nn.Parameter(torch.Tensor(2 * hidden_dim, num_classes))\n",
    "        self.b_p = nn.Parameter(torch.Tensor(num_classes))\n",
    "\n",
    "        self.kaiming_init()\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def kaiming_init(self):\n",
    "        for p in self.parameters():\n",
    "            if len(p.size()) == 2:\n",
    "                p.data.normal_(0, 1 / math.sqrt(2*self.hidden_dim)) # 2 beceause W_ph is a combination of forward and backward pass\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_forward = x\n",
    "        x_backward = torch.flip(x, dims=[1])\n",
    "\n",
    "        # Forward step\n",
    "        c_forward = torch.zeros(self.hidden_dim).to(self.device)\n",
    "        h_forward = torch.zeros(self.hidden_dim).to(self.device)\n",
    "        c_T, h_T = self.lstm_cell(x_forward, c_forward, h_forward)\n",
    "\n",
    "        # Backward step\n",
    "        c_0, h_0 = self.lstm_cell(x_backward, c_T, h_T)\n",
    "\n",
    "        H = torch.cat((h_T, h_0), -1)\n",
    "\n",
    "        out = self.logSoftmax((H @ self.W_ph + self.b_p))\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_length, input_dim, hidden_dim, num_classes,\n",
    "                 batch_size, device):\n",
    "\n",
    "        super(LSTMCell, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(seq_length, input_dim)\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "        # Input modulation gate\n",
    "        self.W_gx = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_gh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_g = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Input gate\n",
    "        self.W_ix = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_ih = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Forget gate\n",
    "        self.W_fx = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_fh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        # Output gate\n",
    "        self.W_ox = nn.Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.W_oh = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.kaiming_init()\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def kaiming_init(self):\n",
    "        for p in self.parameters():\n",
    "            if len(p.size()) == 2:\n",
    "                p.data.normal_(0, 1 / math.sqrt(self.hidden_dim))\n",
    "            else:\n",
    "                p.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, c, h):\n",
    "\n",
    "        h_t = h\n",
    "        c_t = c\n",
    "        x = self.embeddings(x.long())\n",
    "\n",
    "        for time in range(self.seq_length - 1):\n",
    "            x_t = x[:, time, :]\n",
    "            # Input modulation gate\n",
    "            g_t = torch.tanh(x_t @ self.W_gx + h_t @ self.W_gh + self.b_g)\n",
    "            # Input gate\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ix + h_t @ self.W_ih + self.b_i)\n",
    "            # Forget gate\n",
    "            f_t = torch.sigmoid(x_t @ self.W_fx + h_t @ self.W_fh + self.b_f)\n",
    "            # Output gate\n",
    "            o_t = torch.sigmoid(x_t @ self.W_ox + h_t @ self.W_oh + self.b_o)\n",
    "            # Cell state\n",
    "            c_t = g_t * i_t + c_t * f_t\n",
    "            h_t = torch.tanh(c_t) * o_t\n",
    "\n",
    "        return c_t, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biLstm = biLSTM(seq_length=seq_length, input_dim=1, hidden_dim = 128, num_classes= seq_length,\n",
    "            batch_size = 128, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3980, -2.3980, -2.3978, -2.3973, -2.3980, -2.3978, -2.3980, -2.3975,\n",
       "         -2.3983, -2.3975, -2.3986],\n",
       "        [-2.3979, -2.3978, -2.3979, -2.3979, -2.3982, -2.3978, -2.3978, -2.3977,\n",
       "         -2.3983, -2.3976, -2.3977],\n",
       "        [-2.3983, -2.3975, -2.3971, -2.3964, -2.3977, -2.3978, -2.3978, -2.3984,\n",
       "         -2.3959, -2.3994, -2.4006],\n",
       "        [-2.3981, -2.3979, -2.3980, -2.3967, -2.3973, -2.3979, -2.3980, -2.3978,\n",
       "         -2.3981, -2.3975, -2.3993],\n",
       "        [-2.3977, -2.3986, -2.3988, -2.3981, -2.3979, -2.3978, -2.3983, -2.3968,\n",
       "         -2.4002, -2.3959, -2.3968],\n",
       "        [-2.3981, -2.3984, -2.3976, -2.3965, -2.3981, -2.3975, -2.3983, -2.3970,\n",
       "         -2.3977, -2.3977, -2.3998],\n",
       "        [-2.3982, -2.3977, -2.3976, -2.3970, -2.3979, -2.3978, -2.3979, -2.3979,\n",
       "         -2.3974, -2.3982, -2.3992],\n",
       "        [-2.3980, -2.3978, -2.3979, -2.3979, -2.3979, -2.3979, -2.3978, -2.3979,\n",
       "         -2.3984, -2.3976, -2.3978]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biLstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1., 10.,  0.,  7.,  6.,  2.,  3.,  8.,  5.],\n",
       "        [ 7.,  4.,  6.,  5.,  9.,  8., 10.,  2.,  0.,  3.],\n",
       "        [ 3.,  0.,  5.,  1.,  9.,  7.,  2., 10.,  6.,  8.],\n",
       "        [ 7.,  8.,  5.,  9.,  0.,  4.,  1.,  3.,  2.,  6.],\n",
       "        [ 6.,  8.,  3.,  0.,  5., 10.,  7.,  2.,  4.,  1.],\n",
       "        [ 6.,  9., 10.,  1.,  0.,  8.,  3.,  5.,  2.,  7.],\n",
       "        [ 1.,  2.,  5.,  0.,  8.,  7.,  6.,  4.,  9., 10.],\n",
       "        [ 9.,  7.,  5., 10.,  1.,  0.,  3.,  6.,  8.,  2.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(x, dims = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8575, -0.5294, -1.3109], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = nn.Embedding(10, 3)\n",
    "embeddings(torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0090, -0.6284, -1.3574],\n",
       "        [-1.7949,  0.1815, -0.4776],\n",
       "        [-0.5935,  0.6689,  0.8285],\n",
       "        [-1.5750, -0.9543, -0.8172],\n",
       "        [ 0.6617,  0.8185,  1.6829],\n",
       "        [-0.5433,  1.3335, -0.2157],\n",
       "        [-2.3346,  1.6737, -0.9637],\n",
       "        [-0.5777, -0.3100,  0.7148],\n",
       "        [-0.6781,  0.0526,  1.1361],\n",
       "        [ 0.1203,  0.2913, -0.3643]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(torch.tensor(range(0,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(x.long()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(x.long())[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  2.0739e-43,  ...,  0.0000e+00,\n",
       "          3.7975e-42,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -4.9466e-43,  ...,  0.0000e+00,\n",
       "         -9.0398e-42,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -1.8637e-43,  ...,  0.0000e+00,\n",
       "         -3.4066e-42,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.8026e-45,  ...,  0.0000e+00,\n",
       "         -5.1848e-44,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.6332e-43,  ...,  0.0000e+00,\n",
       "         -1.0302e-41,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -4.9466e-43,  ...,  0.0000e+00,\n",
       "         -9.0398e-42,  0.0000e+00]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(embeddings(x.long())[:, 0, :]@torch.Tensor(3,128)  + torch.zeros(128)@torch.Tensor(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(128)@torch.Tensor(128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.Tensor(128, 3)@embeddings(x.long())[:, 0, :].T) .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32])\n"
     ]
    }
   ],
   "source": [
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)\n",
    "\n",
    "bs, seq_sz, _ = arr.size()\n",
    "for t in range(seq_sz): # iterate over the time steps\n",
    "    x_t = arr[:, t, :]\n",
    "    print(x_t.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        # input gate\n",
    "        self.W_ii = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hi = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = Parameter(torch.Tensor(hidden_sz))\n",
    "        # forget gate\n",
    "        self.W_if = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hf = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = Parameter(torch.Tensor(hidden_sz))\n",
    "        # ???\n",
    "        self.W_ig = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hg = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_g = Parameter(torch.Tensor(hidden_sz))\n",
    "        # output gate\n",
    "        self.W_io = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_ho = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, \n",
    "                init_states = None) :\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_if + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_ig + h_t @ self.W_hg + self.b_g)\n",
    "            #print((x_t @ self.W_ig).shape)\n",
    "            print()\n",
    "            print((h_t @ self.W_hg).shape)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_io + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t.unsqueeze(Dim.batch))\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq, (h_t, c_t)\n",
    "    \n",
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)\n",
    "lstm = NaiveLSTM(feat_sz, hidden_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-750faf376643>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/dl2020/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-4da729027a63>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, init_states)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_t\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mhidden_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mhidden_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dim' is not defined"
     ]
    }
   ],
   "source": [
    "hs, (hn, cn) = lstm(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-001a1a9411e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "torch.LongTensor([x[:,0], x[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-8fea531839e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "x[:, 0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-962abb68dbca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/dl2020/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/dl2020/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/miniconda3/envs/dl2020/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "x[:,0]\n",
    "embeddings(torch.tensor(list(x[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0236,  0.0157, -0.2074],\n",
       "         [-0.5139,  1.2556,  0.0493],\n",
       "         [-0.5753,  0.3371, -0.4927],\n",
       "         [-0.9977, -0.0603, -0.6731]],\n",
       "\n",
       "        [[-0.5753,  0.3371, -0.4927],\n",
       "         [ 1.7524, -1.6599,  1.2259],\n",
       "         [-0.5139,  1.2556,  0.0493],\n",
       "         [-0.8980,  0.1093,  1.0010]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9ff305ccf61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "torch.LongTensor(list(x[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_length = x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2372], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(num_embeddings=10, embedding_dim=1)(torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 9])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomCombinations Shape: torch.Size([8, 9])\n",
      "BinaryPalindrome Shape: torch.Size([8, 41, 1])\n",
      "BaumSweetSequence Shape: torch.Size([8, 1, 40])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset1 = datasets.RandomCombinationsDataset(10)\n",
    "dataset2 = datasets.BinaryPalindromeDataset(10)\n",
    "dataset3 = datasets.BaumSweetSequenceDataset(10)\n",
    "\n",
    "data_loader1 = DataLoader(dataset1, 8, num_workers=1, drop_last=True)\n",
    "data_loader2 = DataLoader(dataset2, 8, num_workers=1, drop_last=True)\n",
    "data_loader3 = DataLoader(dataset3, 8, num_workers=1, drop_last=True)\n",
    "\n",
    "values1, _ = next(iter(data_loader1))\n",
    "values2, _ = next(iter(data_loader2))\n",
    "values3, _ = next(iter(data_loader3))\n",
    "\n",
    "print(\"RandomCombinations Shape:\", values1.shape)\n",
    "print(\"BinaryPalindrome Shape:\", values2.shape)\n",
    "print(\"BaumSweetSequence Shape:\", values3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffb7f95c8b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, seq_len, feat_sz, hidden_sz = 5, 10, 32, 16\n",
    "arr = torch.randn(bs, seq_len, feat_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
